# Degrees of freedom of camera
# int
# camera_dof: 2

# max distance (radius) the referenece frame is allowed to be away in terms of the robot's base.
# double
max_ref_frame_distance: 2.5

### Observation positions for capturing calibration images of the pitags
# if this flag is true, then the robot configurations will be sampled on a equally spaced grid from the given ranges, if false, the user-provided configurations in robot_configurations will be used
# bool
use_range: true

# ranges for the degrees of freedom of the robot
# each parameter is set as [min_value, step, max_value]
# double
x_range: [-1.25, 0.5, -0.75]#[-1.0, 1.0, -1.0]       # in [m]
y_range: [-1.5, 0.5, -1.0]#[-1.0, 1.0, -1.0]          # in [m], fixed y-coordinate
phi_range: [0.0, 1.0, 0.0]          # in [rad], fixed phi-angle
camera_ranges: [-1.2, 1.0, 0.2,
                -0.8, 0.8, 0.0]     # first pan then tilt in [rad]

# list of robot configurations for observing the pitags measured relative to the landmark_reference_nav coordinate system that is similarly aligned as the robot's base_link facing the marker
# includes 5 parameters per entry: robot pose: x, y, phi and camera angles at the end
robot_configurations: [-1.5, -0.17, 0, 0.15, 0.25,
                       -1.5, -0.17, 0, 0.0, 0.3,
                       -1.5, -0.17, 0, -0.15, 0.3,
                       -1.5, -0.17, 0, -0.3, 0.3,
                       -1.5, -0.17, 0, -0.5, 0.3,
                       -1.5, -0.17, 0, 0.15, 0.05,
                       -1.5, -0.17, 0, 0.0, 0.05,
                       -1.5, -0.17, 0, -0.15, 0.05,
                       -1.5, -0.17, 0, -0.3, 0.05,
                       -1.5, -0.17, 0, -0.5, 0.05,
                       -1.5, -0.17, 0, 0.15, -0.2,
                       -1.5, -0.17, 0, 0.0, -0.2,
                       -1.5, -0.17, 0, -0.15, -0.2,
                       -1.5, -0.17, 0, -0.35, -0.2,
                       -1.5, -0.17, 0, -0.5, -0.2,
                       -1.0, -0.17, 0, 0.0, 0.2,
                       -1.0, -0.17, 0, -0.2, 0.2,
                       -1.0, -0.17, 0, -0.45, 0.2,
                       -1.0, -0.17, 0, 0.0, 0.05,
                       -1.0, -0.17, 0, -0.2, 0.05,
                       -1.0, -0.17, 0, -0.45, 0.05,
                       -1.0, -0.17, 0, 0.0, -0.15,
                       -1.0, -0.17, 0, -0.2, -0.15,
                       -1.0, -0.17, 0, -0.45, -0.15,
                       -0.85, -0.17, 0, 0.0, 0.15,
                       -0.85, -0.17, 0, -0.15, 0.15,
                       -0.85, -0.17, 0, -0.35, 0.2,
                       -0.85, -0.17, 0, 0.0, 0.05,
                       -0.85, -0.17, 0, -0.15, 0.05,
                       -0.85, -0.17, 0, -0.35, 0.05,
                       -0.85, -0.17, 0, 0.0, -0.1,
                       -0.85, -0.17, 0, -0.15, -0.1,
                       -0.85, -0.17, 0, -0.35, -0.1]


### Robot link and topic names
# the robot base frame, needed for security measure (it's the reference frame to check the child_frame against before moving the robot)
base_frame: "base_linkz"

# The name of the reference frame. Has to match the entry found in the relative_localization yaml files.
# string
reference_frame: "/landmark_reference_nav"

# this is the camera coordinate system which refers to the color image sensor [the transformations between camera_frame and camera_optical_frame should be available from tf]
#camera_optical_frame: "kinect_depth_optical_frame"

# the transformations between base_frame and the first entry of the uncertainties list and the last entry and camera_optical_frame has to be be available from TF
# the list contains couples from parent to child. Each couple defines an uncertainty in the kinematic chain which will be calibrated by the program
# the list must be in order, i.e. uncertainties earlier in the list must also be earlier in the kinematic chain
# take into account that the transformations between the uncertainties have to be available from TF as well

# [parent frame, child frame, last parent-branch frame, last child-branch frame, parent marker, child marker]
uncertainties_list: ["base_linkz","base_neck_link", "landmark_reference_front", "kinect_depth_optical_frame", "tag_25", "marker_25",
                     "base_linkz","base_neck_link", "landmark_reference_front", "kinect_depth_optical_frame", "tag_36", "marker_36",
                     "base_linkz","base_neck_link", "landmark_reference_front", "kinect_depth_optical_frame", "tag_38", "marker_38",
                     "base_linkz","base_neck_link", "landmark_reference_left", "kinect_depth_optical_frame", "tag_48", "marker_48",
                     "base_linkz","base_neck_link", "landmark_reference_left", "kinect_depth_optical_frame", "tag_55", "marker_55",
                     "base_linkz","base_neck_link", "landmark_reference_left", "kinect_depth_optical_frame", "tag_64", "marker_64",
                     "base_linkz","base_neck_link", "landmark_reference_ground", "kinect_depth_optical_frame", "tag_69", "marker_69",
                     "base_linkz","base_neck_link", "landmark_reference_ground", "kinect_depth_optical_frame", "tag_73", "marker_73",
                     "base_linkz","base_neck_link", "landmark_reference_ground", "kinect_depth_optical_frame", "tag_79", "marker_79",

                     "kinect_link","kinect_depth_frame", "landmark_reference_front", "kinect_depth_optical_frame", "tag_25", "marker_25",
                     "kinect_link","kinect_depth_frame", "landmark_reference_front", "kinect_depth_optical_frame", "tag_36", "marker_36",
                     "kinect_link","kinect_depth_frame", "landmark_reference_front", "kinect_depth_optical_frame", "tag_38", "marker_38",
                     "kinect_link","kinect_depth_frame", "landmark_reference_left", "kinect_depth_optical_frame", "tag_48", "marker_48",
                     "kinect_link","kinect_depth_frame", "landmark_reference_left", "kinect_depth_optical_frame", "tag_55", "marker_55",
                     "kinect_link","kinect_depth_frame", "landmark_reference_left", "kinect_depth_optical_frame", "tag_64", "marker_64",
                     "kinect_link","kinect_depth_frame", "landmark_reference_ground", "kinect_depth_optical_frame", "tag_69", "marker_69",
                     "kinect_link","kinect_depth_frame", "landmark_reference_ground", "kinect_depth_optical_frame", "tag_73", "marker_73",
                     "kinect_link","kinect_depth_frame", "landmark_reference_ground", "kinect_depth_optical_frame", "tag_79", "marker_79"]

# defines the order in which the uncertainties will be calibrated
# each couple or uncertainty in the uncertainties_list increases the calibration_order list
# the value represents the index of an uncertainty in the uncertainties_list and the position of the index in the calibration_order list defines the actual order
# i.e. the first element in the calibration_order will be calibrated first, then comes the second element and so on...
# the more uncertain a transform is the earlier should its index be placed in the calibration_order list
# so the index of the most uncertain transform should be the first element here
#calibration_order: [1,2]

# base name of all frames generated by cob_fiducials, each Pi tag number will be attached to this string.
marker_frame_base_name: "tag"


### Program sequence
# loads snapshotted data from disk if set to true, for offline calibration
# bool
#load_data: true

# number of optimization iterations
# int
optimization_iterations: 10000

# storage folder that holds the calibration output
# string
calibration_storage_path: "robotino_calibration/camera_pitag_calibration"
